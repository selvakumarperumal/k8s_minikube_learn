# ============================================================================
# DAEMONSET - Simple Log Collector using Busybox
# ============================================================================
# This is a SIMPLIFIED example that demonstrates the DaemonSet pattern
# for log collection. Uses busybox instead of Fluentd for simplicity.
#
# For production, use:
# - Fluentd: https://github.com/fluent/fluentd-kubernetes-daemonset
# - Fluent Bit: https://docs.fluentbit.io/manual/installation/kubernetes
# - Promtail (for Loki): https://grafana.com/docs/loki/latest/clients/promtail/
# ============================================================================

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: log-collector
  namespace: kube-system
  labels:
    app: log-collector
spec:
  selector:
    matchLabels:
      app: log-collector

  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1

  template:
    metadata:
      labels:
        app: log-collector
    spec:
      terminationGracePeriodSeconds: 30

      # Run on all nodes including control-plane
      tolerations:
        - operator: Exists

      containers:
        - name: log-collector
          image: busybox:latest

          command:
            - sh
            - -c
            - |
              echo "Log collector starting on node: $NODE_NAME"
              echo "Monitoring /var/log/containers/*.log"
              echo "-------------------------------------------"

              # Tail all container logs and output to stdout
              # In production, this would be shipped to Elasticsearch/Loki/etc.
              while true; do
                for log in /var/log/containers/*.log; do
                  if [ -f "$log" ]; then
                    # Output last 5 lines from each log file
                    echo "=== $(basename $log) ==="
                    tail -5 "$log" 2>/dev/null || true
                  fi
                done
                echo "--- Collected at $(date) from $NODE_NAME ---"
                sleep 30
              done

          env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName

          resources:
            requests:
              cpu: 50m
              memory: 64Mi
            limits:
              cpu: 100m
              memory: 128Mi

          volumeMounts:
            - name: varlog
              mountPath: /var/log
              readOnly: true

      volumes:
        - name: varlog
          hostPath:
            path: /var/log
# ============================================================================
# HOW TO USE
# ============================================================================
#
# STEP 1: Apply
#   kubectl apply -f daemonset-fluentd.yaml
#
# STEP 2: Check status
#   kubectl get daemonset log-collector -n kube-system
#   kubectl get pods -n kube-system -l app=log-collector
#
# STEP 3: View collected logs
#   kubectl logs -n kube-system -l app=log-collector -f
#
# STEP 4: Generate test logs
#   kubectl run test-logger --image=busybox -- sh -c "while true; do echo 'Hello from test-logger at $(date)'; sleep 5; done"
#
# STEP 5: See the test logs in collector output (wait ~30 seconds)
#   kubectl logs -n kube-system -l app=log-collector -f
#
# CLEANUP:
#   kubectl delete -f daemonset-fluentd.yaml
#   kubectl delete pod test-logger
#
# ============================================================================
# FOR PRODUCTION - Use proper log collectors:
# ============================================================================
#
# FLUENT BIT (lightweight):
#   helm repo add fluent https://fluent.github.io/helm-charts
#   helm install fluent-bit fluent/fluent-bit
#
# FLUENTD:
#   kubectl apply -f https://raw.githubusercontent.com/fluent/fluentd-kubernetes-daemonset/master/fluentd-daemonset-elasticsearch.yaml
#
# PROMTAIL (for Loki):
#   helm repo add grafana https://grafana.github.io/helm-charts
#   helm install promtail grafana/promtail
#
# ============================================================================
